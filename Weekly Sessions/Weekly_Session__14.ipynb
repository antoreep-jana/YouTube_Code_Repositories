{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weekly_Session_#14.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVD6QJqCbIQpzwXAnGDEQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoreep-jana/YouTube_Code_Repositories/blob/main/Weekly%20Sessions/Weekly_Session__14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-nuG-lxrVNk"
      },
      "source": [
        "Custom Model Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuzraW2rUiNr"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guxjGpIarSiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0026f879-6956-442a-d6f7-0b6af82579bf"
      },
      "source": [
        "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "mae_metric = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "\n",
        "  def train_step(self, data):\n",
        "\n",
        "    x, y = data \n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x, training = True)\n",
        "\n",
        "      #loss = self.compiled_loss(y, y_pred, regularization_losses = self.losses)\n",
        "      loss = tf.keras.losses.mean_squared_error(y, y_pred)\n",
        "\n",
        "    trainable_vars = self.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "    # Update metrics (includes the metric that tracks the loss)\n",
        "    #self.compiled_metrics.update_state(y, y_pred)\n",
        "    loss_tracker.update_state(loss)\n",
        "    mae_metric.update_state(y, y_pred)\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {\"loss\" : loss_tracker.result(), \"mae\" : mae_metric.result()}\n",
        "    #return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [loss_tracker, mae_metric]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Construct and compile an instance of CustomModel\n",
        "inputs = tf.keras.Input(shape=(32,))\n",
        "outputs = tf.keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Just use `fit` as usual\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.5284 - mae: 0.6080\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2576 - mae: 0.4042\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.2314 - mae: 0.3831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd8abadd6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFPf6C77rjP"
      },
      "source": [
        "Method-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DlN6zMIY9vh"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsMY6P0nVgeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e32bd3c-70b5-4f33-e486-e77d06b878cb"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "print(x_train.shape, y_train.shape) # (50000, 32, 32, 3) (50000, 1)\n",
        "print(x_test.shape, y_test.shape)   # (10000, 32, 32, 3) (10000, 1)\n",
        "\n",
        "\n",
        "# train set / data \n",
        "x_train = x_train.astype('float32') / 255\n",
        "\n",
        "# validation set / data \n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "# validation set / target \n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grr0ii1djOlR"
      },
      "source": [
        "base = tf.keras.applications.VGG16(include_top = False, input_shape = (32,32,3), weights = 'imagenet')\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    base, \n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(256, activation= 'relu'),\n",
        "                                    tf.keras.layers.Dropout(0.2),\n",
        "                                    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-uyo8v9ZW3Q",
        "outputId": "d02200b3-20de-4ebb-96e7-2e6d59d05850"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 15,111,242\n",
            "Trainable params: 15,111,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU6sNJliYiSr"
      },
      "source": [
        "# define optimizer & loss func\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "val_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "## Adding metrics \n",
        "\n",
        "train_acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60sB8vYhcVHt"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "uK8EsTb074sO",
        "outputId": "ebce8aad-4c5f-45ef-8a68-92d7889f3cd4"
      },
      "source": [
        "\"\"\"\n",
        "Steps for custom training\n",
        "\n",
        "1. Epochs - 1 for loop\n",
        "2. Within epochs - batches - another for loop\n",
        "3. Calculate gradients under tape\n",
        "    a. pred logits from forward pass\n",
        "    b. calc loss value\n",
        "4. calculate gradient using tape.gradient() of training variables wrt loss \n",
        "5. Update the weight based on the gradient. Run one step of gradient descent. \n",
        "\n",
        "\"\"\"\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch}/{epochs}\")\n",
        "  for step , (x_batch_train, y_batch_train) in enumerate(tqdm(train_dataset)):\n",
        "\n",
        "    \"\"\" Training Begins\"\"\"  \n",
        "    with tf.GradientTape() as tape:\n",
        "      preds = model(x_batch_train, training = True) \n",
        "\n",
        "      loss = loss_fn(y_batch_train, preds)\n",
        "\n",
        "    grads= tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    train_acc.update_state(y_batch_train, preds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"Training Loss : {loss}\")\n",
        "\n",
        "  print(f\"Training Accuracy : {train_acc.result()}\")\n",
        "\n",
        "  train_acc.reset_states()\n",
        "\n",
        "\n",
        "  \"\"\" Validation Begins\"\"\"\n",
        "\n",
        "  for step, (x_batch_val, y_batch_val) in enumerate(tqdm(val_dataset)):\n",
        "\n",
        "    preds = model(x_batch_val, training = False)\n",
        "\n",
        "    loss = loss_fn(y_batch_val, preds)\n",
        "\n",
        "    val_acc.update_state(y_batch_val , preds)\n",
        "\n",
        "  \n",
        "\n",
        "  print(f\"Validaton Loss : {loss}\")\n",
        "  print(f'Validation Accuracy : {val_acc.result()}')\n",
        "\n",
        "  val_acc.reset_states()\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [02:22<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss : 1.5089772939682007\n",
            "Training Accuracy : 0.2332800030708313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 41.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validaton Loss : 1.9351825714111328\n",
            "Validation Accuracy : 0.30869999527931213\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [02:22<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss : 1.1028939485549927\n",
            "Training Accuracy : 0.36191999912261963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 41.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validaton Loss : 1.672498345375061\n",
            "Validation Accuracy : 0.4203999936580658\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:46<00:00, 14.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss : 1.6734575033187866\n",
            "Training Accuracy : 0.4395599961280823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:07<00:00, 42.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validaton Loss : 1.5182762145996094\n",
            "Validation Accuracy : 0.4309999942779541\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1008/1563 [01:09<00:38, 14.60it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4da2764beb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\" Training Begins\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         training=training_mode):\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36minput_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manual_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_spec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36minput_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m       return [input_spec.InputSpec(\n\u001b[1;32m    276\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_with_no_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_last_axis_squeeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m           name=x._keras_history.layer.name) for x in self.inputs]\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    275\u001b[0m       return [input_spec.InputSpec(\n\u001b[1;32m    276\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_with_no_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_last_axis_squeeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m           name=x._keras_history.layer.name) for x in self.inputs]\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mshape_with_no_batch_size\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshape_with_no_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;34m\"\"\"Returns the rank of this shape, or None if it is unspecified.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKmb2_bLiUfF"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    preds = model(x, training = True)\n",
        "\n",
        "    loss = loss_fn(y, preds)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  train_acc.update_state(y, preds)\n",
        "  return loss\n",
        "\n",
        "@tf.function\n",
        "def val_step(x, y):\n",
        "  preds_val = model(x, training = False)\n",
        "  #loss_val = val_loss_fn(y, preds)\n",
        "  #print(\"X Shape -> \", x.shape)\n",
        "  #print(\"YShape ->\", y.shape)\n",
        "  #print(\"Preds Shape -> \", preds_val.shape)\n",
        "  val_loss = loss_fn(y, preds_val)\n",
        "  val_acc.update_state(y, preds_val)\n",
        "  return val_loss\n",
        "  #return loss_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q488HkS3iUbk",
        "outputId": "78224713-ea7f-4a7c-91f8-c1152b9d7f2a"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  print(f\"Epoch {epoch}/{epochs}\")\n",
        "  for step, (x_train_batch, y_train_batch) in enumerate(tqdm(train_dataset)):\n",
        "    train_loss = train_step(x_train_batch, y_train_batch)\n",
        "  \n",
        "  print(f\"Training Accuracy -> {train_acc.result()}\", f\" Loss : {train_loss}\")\n",
        "\n",
        "  train_acc.reset_states()\n",
        "  for step, (x_val_batch, y_val_batch) in enumerate(tqdm(val_dataset)):\n",
        "    val_loss = val_step(x_val_batch, y_val_batch)\n",
        "\n",
        "  print(f\"Validation Accuracy -> {val_acc.result()}\", f\" Loss : {val_loss}\")\n",
        "\n",
        "  val_acc.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:27<00:00, 17.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy -> 0.0967399999499321  Loss : 2.304940700531006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:04<00:00, 65.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy -> 0.09932126849889755  Loss : 2.2992143630981445\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [01:26<00:00, 18.26it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtHHOSTuiUVM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}